<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Hypotheses | CRIM20452 Modelling Criminological Data</title>
  <meta name="description" content="This is a companion workbook for the 2nd year undergraduate module CRIM20452 Modelling Criminological Data at the University of Manchester" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Hypotheses | CRIM20452 Modelling Criminological Data" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a companion workbook for the 2nd year undergraduate module CRIM20452 Modelling Criminological Data at the University of Manchester" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Hypotheses | CRIM20452 Modelling Criminological Data" />
  
  <meta name="twitter:description" content="This is a companion workbook for the 2nd year undergraduate module CRIM20452 Modelling Criminological Data at the University of Manchester" />
  

<meta name="author" content="Laura Bui &amp; Reka Solymosi" />


<meta name="date" content="2021-03-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inferential-statistics.html"/>
<link rel="next" href="relationships-with-categorical-variables.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelling Criminological Data</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html"><i class="fa fa-check"></i><b>1</b> A First Lesson About R</a><ul>
<li class="chapter" data-level="1.1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#install-r-r-studio"><i class="fa fa-check"></i><b>1.1</b> Install R &amp; R Studio</a><ul>
<li class="chapter" data-level="1.1.1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#activity-1-identifying-your-operating-system"><i class="fa fa-check"></i><b>1.1.1</b> Activity 1: Identifying your operating system</a></li>
<li class="chapter" data-level="1.1.2" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#activity-2-install-r-r-studio"><i class="fa fa-check"></i><b>1.1.2</b> Activity 2: Install R &amp; R Studio</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#getting-to-know-rstudio"><i class="fa fa-check"></i><b>1.2</b> Getting to know <code>RStudio</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#the-four-panes-of-r-studio"><i class="fa fa-check"></i><b>1.2.1</b> The four panes of R Studio</a></li>
<li class="chapter" data-level="1.2.2" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#customising-r-studio"><i class="fa fa-check"></i><b>1.2.2</b> Customising R Studio</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#todays-3-topics"><i class="fa fa-check"></i><b>1.3</b> Today’s 3 (TOPICS)</a><ul>
<li class="chapter" data-level="1.3.1" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#operators-and-functions"><i class="fa fa-check"></i><b>1.3.1</b> Operators and Functions</a></li>
<li class="chapter" data-level="1.3.2" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#objects"><i class="fa fa-check"></i><b>1.3.2</b> Objects</a></li>
<li class="chapter" data-level="1.3.3" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#packages-1"><i class="fa fa-check"></i><b>1.3.3</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="a-first-lesson-about-r.html"><a href="a-first-lesson-about-r.html#summary"><i class="fa fa-check"></i><b>1.4</b> SUMMARY</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html"><i class="fa fa-check"></i><b>2</b> Getting to know your data</a><ul>
<li class="chapter" data-level="2.1" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#the-tidyverse"><i class="fa fa-check"></i><b>2.1</b> The Tidyverse</a></li>
<li class="chapter" data-level="2.2" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#r-projects-getting-your-work-files-organised"><i class="fa fa-check"></i><b>2.2</b> R Projects – Getting Your Work Files Organised</a><ul>
<li class="chapter" data-level="2.2.1" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#activity-1-making-yourself-a-project"><i class="fa fa-check"></i><b>2.2.1</b> Activity 1: Making yourself a project</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#importing-data"><i class="fa fa-check"></i><b>2.3</b> Importing Data</a><ul>
<li class="chapter" data-level="2.3.1" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#activity-2-importing-and-viewing-data"><i class="fa fa-check"></i><b>2.3.1</b> Activity 2: Importing and Viewing Data</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#todays-3-topics-1"><i class="fa fa-check"></i><b>2.4</b> Today’s 3 (TOPICS)</a><ul>
<li class="chapter" data-level="2.4.1" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#variables"><i class="fa fa-check"></i><b>2.4.1</b> Variables</a></li>
<li class="chapter" data-level="2.4.2" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#labels"><i class="fa fa-check"></i><b>2.4.2</b> Labels</a></li>
<li class="chapter" data-level="2.4.3" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#subsetting"><i class="fa fa-check"></i><b>2.4.3</b> Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#summary-1"><i class="fa fa-check"></i><b>2.5</b> SUMMARY</a><ul>
<li class="chapter" data-level="2.5.1" data-path="getting-to-know-your-data.html"><a href="getting-to-know-your-data.html#answers-to-activities-if-applicable"><i class="fa fa-check"></i><b>2.5.1</b> Answers to activities (if applicable)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>3</b> Data Visualization</a><ul>
<li class="chapter" data-level="3.1" data-path="data-visualization.html"><a href="data-visualization.html#grammar-of-graphics"><i class="fa fa-check"></i><b>3.1</b> Grammar of Graphics</a><ul>
<li class="chapter" data-level="3.1.1" data-path="data-visualization.html"><a href="data-visualization.html#activity-1-getting-ready"><i class="fa fa-check"></i><b>3.1.1</b> Activity 1: Getting Ready</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="data-visualization.html"><a href="data-visualization.html#ggplot2"><i class="fa fa-check"></i><b>3.2</b> ggplot2</a></li>
<li class="chapter" data-level="3.3" data-path="data-visualization.html"><a href="data-visualization.html#todays-3"><i class="fa fa-check"></i><b>3.3</b> Today’s 3</a><ul>
<li class="chapter" data-level="3.3.1" data-path="data-visualization.html"><a href="data-visualization.html#layers"><i class="fa fa-check"></i><b>3.3.1</b> Layers</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-visualization.html"><a href="data-visualization.html#graphs-for-categorical-data"><i class="fa fa-check"></i><b>3.3.2</b> Graphs for Categorical Data</a></li>
<li class="chapter" data-level="3.3.3" data-path="data-visualization.html"><a href="data-visualization.html#graphs-for-numeric-data"><i class="fa fa-check"></i><b>3.3.3</b> Graphs for Numeric Data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data-visualization.html"><a href="data-visualization.html#summary-2"><i class="fa fa-check"></i><b>3.4</b> SUMMARY</a><ul>
<li class="chapter" data-level="3.4.1" data-path="data-visualization.html"><a href="data-visualization.html#answers-to-activities"><i class="fa fa-check"></i><b>3.4.1</b> ANSWERS TO ACTIVITIES:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html"><i class="fa fa-check"></i><b>4</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="4.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#revisiting-descriptive-statistics"><i class="fa fa-check"></i><b>4.1</b> Revisiting Descriptive Statistics</a><ul>
<li class="chapter" data-level="4.1.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#activity-1-our-preparation-routine"><i class="fa fa-check"></i><b>4.1.1</b> Activity 1: Our preparation routine</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#todays-3-1"><i class="fa fa-check"></i><b>4.2</b> Today’s 3</a><ul>
<li class="chapter" data-level="4.2.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#central-tendency"><i class="fa fa-check"></i><b>4.2.1</b> Central Tendency</a></li>
<li class="chapter" data-level="4.2.2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#outliers"><i class="fa fa-check"></i><b>4.2.2</b> Outliers</a></li>
<li class="chapter" data-level="4.2.3" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#measures-of-dispersion"><i class="fa fa-check"></i><b>4.2.3</b> Measures of Dispersion</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#summary-3"><i class="fa fa-check"></i><b>4.3</b> SUMMARY</a><ul>
<li class="chapter" data-level="4.3.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#answers-to-activities-where-applicable"><i class="fa fa-check"></i><b>4.3.1</b> Answers to Activities (where applicable)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="inferential-statistics.html"><a href="inferential-statistics.html"><i class="fa fa-check"></i><b>5</b> Inferential Statistics</a><ul>
<li class="chapter" data-level="5.1" data-path="inferential-statistics.html"><a href="inferential-statistics.html#generalising-about-the-world-from-data"><i class="fa fa-check"></i><b>5.1</b> Generalising About the World from Data</a><ul>
<li class="chapter" data-level="5.1.1" data-path="inferential-statistics.html"><a href="inferential-statistics.html#activity-1-our-preparation-routine-1"><i class="fa fa-check"></i><b>5.1.1</b> Activity 1: Our preparation routine</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="inferential-statistics.html"><a href="inferential-statistics.html#todays-3-2"><i class="fa fa-check"></i><b>5.2</b> Today’s 3</a><ul>
<li class="chapter" data-level="5.2.1" data-path="inferential-statistics.html"><a href="inferential-statistics.html#samples"><i class="fa fa-check"></i><b>5.2.1</b> Samples</a></li>
<li class="chapter" data-level="5.2.2" data-path="inferential-statistics.html"><a href="inferential-statistics.html#the-standard-error"><i class="fa fa-check"></i><b>5.2.2</b> The Standard Error</a></li>
<li class="chapter" data-level="5.2.3" data-path="inferential-statistics.html"><a href="inferential-statistics.html#confidence-intervals"><i class="fa fa-check"></i><b>5.2.3</b> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="inferential-statistics.html"><a href="inferential-statistics.html#summary-4"><i class="fa fa-check"></i><b>5.3</b> SUMMARY</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypotheses.html"><a href="hypotheses.html"><i class="fa fa-check"></i><b>6</b> Hypotheses</a><ul>
<li class="chapter" data-level="6.1" data-path="hypotheses.html"><a href="hypotheses.html#hypothesis-testing"><i class="fa fa-check"></i><b>6.1</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="6.1.1" data-path="hypotheses.html"><a href="hypotheses.html#the-null-hypothesis"><i class="fa fa-check"></i><b>6.1.1</b> The null hypothesis</a></li>
<li class="chapter" data-level="6.1.2" data-path="hypotheses.html"><a href="hypotheses.html#directional-hypotheses"><i class="fa fa-check"></i><b>6.1.2</b> Directional hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="hypotheses.html"><a href="hypotheses.html#todays-3-3"><i class="fa fa-check"></i><b>6.2</b> Today’s 3</a><ul>
<li class="chapter" data-level="6.2.1" data-path="hypotheses.html"><a href="hypotheses.html#statistical-significance"><i class="fa fa-check"></i><b>6.2.1</b> Statistical Significance</a></li>
<li class="chapter" data-level="6.2.2" data-path="hypotheses.html"><a href="hypotheses.html#a-binomial-test"><i class="fa fa-check"></i><b>6.2.2</b> A Binomial Test</a></li>
<li class="chapter" data-level="6.2.3" data-path="hypotheses.html"><a href="hypotheses.html#single-sample-significance-tests"><i class="fa fa-check"></i><b>6.2.3</b> Single-sample significance tests</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="hypotheses.html"><a href="hypotheses.html#summary-5"><i class="fa fa-check"></i><b>6.3</b> SUMMARY</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="relationships-with-categorical-variables.html"><a href="relationships-with-categorical-variables.html"><i class="fa fa-check"></i><b>7</b> Relationships with Categorical Variables</a><ul>
<li class="chapter" data-level="7.1" data-path="relationships-with-categorical-variables.html"><a href="relationships-with-categorical-variables.html#associating-with-categorical-variables"><i class="fa fa-check"></i><b>7.1</b> Associating with Categorical Variables</a></li>
<li class="chapter" data-level="7.2" data-path="relationships-with-categorical-variables.html"><a href="relationships-with-categorical-variables.html#todays-3-4"><i class="fa fa-check"></i><b>7.2</b> Today’s 3</a><ul>
<li class="chapter" data-level="7.2.1" data-path="relationships-with-categorical-variables.html"><a href="relationships-with-categorical-variables.html#independent-and-dependent-variables"><i class="fa fa-check"></i><b>7.2.1</b> Independent and Dependent Variables</a></li>
<li class="chapter" data-level="7.2.2" data-path="relationships-with-categorical-variables.html"><a href="relationships-with-categorical-variables.html#the-t-test"><i class="fa fa-check"></i><b>7.2.2</b> The T-Test</a></li>
<li class="chapter" data-level="7.2.3" data-path="relationships-with-categorical-variables.html"><a href="relationships-with-categorical-variables.html#chi-square"><i class="fa fa-check"></i><b>7.2.3</b> Chi-square</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="relationships-with-categorical-variables.html"><a href="relationships-with-categorical-variables.html#summary-6"><i class="fa fa-check"></i><b>7.3</b> SUMMARY</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="strength-of-relationships.html"><a href="strength-of-relationships.html"><i class="fa fa-check"></i><b>8</b> Strength of Relationships</a><ul>
<li class="chapter" data-level="8.1" data-path="strength-of-relationships.html"><a href="strength-of-relationships.html#measures-of-association"><i class="fa fa-check"></i><b>8.1</b> Measures of Association</a></li>
<li class="chapter" data-level="8.2" data-path="strength-of-relationships.html"><a href="strength-of-relationships.html#todays-3-5"><i class="fa fa-check"></i><b>8.2</b> Today’s 3</a><ul>
<li class="chapter" data-level="8.2.1" data-path="strength-of-relationships.html"><a href="strength-of-relationships.html#between-categorical-nominal-variables"><i class="fa fa-check"></i><b>8.2.1</b> Between Categorical, Nominal Variables</a></li>
<li class="chapter" data-level="8.2.2" data-path="strength-of-relationships.html"><a href="strength-of-relationships.html#between-categorical-ordinal-variables"><i class="fa fa-check"></i><b>8.2.2</b> Between Categorical, Ordinal Variables</a></li>
<li class="chapter" data-level="8.2.3" data-path="strength-of-relationships.html"><a href="strength-of-relationships.html#between-numeric-variables"><i class="fa fa-check"></i><b>8.2.3</b> Between Numeric Variables</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="strength-of-relationships.html"><a href="strength-of-relationships.html#summary-7"><i class="fa fa-check"></i><b>8.3</b> SUMMARY</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>9</b> Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="regression.html"><a href="regression.html#multiple-and-simultaneous-relationships"><i class="fa fa-check"></i><b>9.1</b> Multiple and Simultaneous Relationships</a></li>
<li class="chapter" data-level="9.2" data-path="regression.html"><a href="regression.html#todays-3-6"><i class="fa fa-check"></i><b>9.2</b> Today’s 3</a><ul>
<li class="chapter" data-level="9.2.1" data-path="regression.html"><a href="regression.html#assumptions-of-ols-regression"><i class="fa fa-check"></i><b>9.2.1</b> Assumptions of OLS Regression</a></li>
<li class="chapter" data-level="9.2.2" data-path="regression.html"><a href="regression.html#interpreting-ols-regression"><i class="fa fa-check"></i><b>9.2.2</b> Interpreting OLS Regression</a></li>
<li class="chapter" data-level="9.2.3" data-path="regression.html"><a href="regression.html#logistic-regression"><i class="fa fa-check"></i><b>9.2.3</b> Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="regression.html"><a href="regression.html#summary-8"><i class="fa fa-check"></i><b>9.3</b> SUMMARY</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">CRIM20452 Modelling Criminological Data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypotheses" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Hypotheses</h1>
<div id="statistical-significance-binominal-test-single-sample-significance-tests" class="section level4 unnumbered">
<h4><em>Statistical Significance, Binominal Test, Single Sample Significance Tests</em></h4>
</div>
<div id="learning-outcomes-5" class="section level4 unnumbered">
<h4>Learning Outcomes:</h4>
<ul>
<li>Know what hypotheses are and how to use them in inferential statistics</li>
<li>Understand what statistical significance is and how to interpret p-values</li>
<li>Know what hypothesis tests are and how to conduct a couple of them</li>
</ul>
</div>
<div id="todays-learning-tools-5" class="section level4 unnumbered">
<h4>Today’s Learning Tools:</h4>
<div id="data-5" class="section level5 unnumbered">
<h5><em>Data:</em></h5>
<ul>
<li>Synthetic data</li>
</ul>
</div>
<div id="packages-6" class="section level5 unnumbered">
<h5><em>Packages:</em></h5>
<ul>
<li><code>DescTools</code></li>
<li><code>dplyr</code></li>
<li><code>ggplot2</code></li>
<li><code>tigerstats</code></li>
</ul>
</div>
<div id="functions-introduced-and-packages-to-which-they-belong-5" class="section level5 unnumbered">
<h5><em>Functions introduced (and packages to which they belong)</em></h5>
<ul>
<li><code>BinomCI()</code> : Compute confidence intervals for binomial proportions (<code>DescTools</code>)</li>
<li><code>nrow()</code> : Counts the number of rows (<code>base R</code>)</li>
<li><code>pnorm()</code> : Probability of random variable following normal distribution (<code>stats</code>)</li>
<li><code>pnormGC()</code> : Compute probabilities for normal random variables (<code>tigerstats</code>)</li>
<li><code>prop.test()</code> : Test null hypothesis that proportions in groups are the same (<code>base R</code>)</li>
<li><code>prop_z_test()</code> : Single-sample z-test for proportions we created in this chapter</li>
<li><code>scale()</code> : Mean centers or rescales a numeric variable (<code>base R</code>)</li>
<li><code>which()</code> : Provides the position of the elements such as in a row (<code>base R</code>)</li>
<li><code>z_test()</code> : Function created in this chapter for a single-sample z-test</li>
</ul>
<p><br>
<br></p>
<hr />
</div>
</div>
<div id="hypothesis-testing" class="section level2">
<h2><span class="header-section-number">6.1</span> Hypothesis Testing</h2>
<p>Last time, we were introduced to inferential statistics: we used a sample of observations, taken from the population, to draw conclusions about this population. We did this to understand how a sample statistic (such as the sample mean) can be used to make inferences about the parameters (such as the true mean value in the population).</p>
<p>We often, however, use samples not only to make inferences about the population of interest, but to also answer research questions. For example, we might want to know if students experience more burglary than non-students? Do men worry about crime more so than women? Do different ethnic groups have different levels of trust in the police?</p>
<p>In this session, we are going to learn the first step in making predictions about our world: hypothesis testing. In crime and criminal justice research, <strong>hypotheses</strong> (essentially predictions) are made and tested frequently. Hypotheses estimate what we will observe in our data.</p>
<p>Having been informed by previous research and evidence, we might predict the following: that a new intervention programme will reduce reoffending; low self-control is predictive of later criminal behaviour; adverts on reporting sexual harassment on public transport will increase awareness and, in turn, reduce sexual victimisation rates. These are all hypotheses about a specific population (offenders who may reoffend; potential offenders who have varying levels of self-control; people who take public transport). As we learned from last time, though, we cannot test an entire population. Therefore, instead, with hypothesis testing, we take a sample from our population of interest, and use this sample to draw our inferences.</p>
<p>When we test our hypothesis, we test to see if our prediction is true for the population of interest. For example, we hypothesize that a new intervention programme will reduce reoffending among at-risk young people in Manchester. There are different research designs that can answer this question; for example, last semester, we learned about <a href="https://www.bi.team/publications/test-learn-adapt-developing-public-policy-with-randomised-controlled-trials/">randomised control trials</a>.</p>
<p>If we use a randomised control trial, we take a sample of at-risk young people in Manchester and randomly assign them to either a control (no intervention) or treatment (our new intervention programme) group. We can then compare the level of reoffending between these two groups to confirm whether our hypothesis is true. This is known as <strong>hypothesis testing</strong>, as we test the hypothesis that the new intervention had an effect (i.e., reduced reoffending). After, we can generalise our result to the population of all at-risk young people in Manchester.</p>
<p>Although it seems like the example of the new intervention programme is about demonstrating that the programme works in reducing reoffending, in actuality, we do not set out to <em>prove</em> that it works. What we try to do with hypothesis testing is to <em>try to disprove</em> that our intervention works. It may sound like scientists are a bunch of negative pessimists, it is about reducing doubt and increasing certainty in our findings. This is the paradigm of scientific research that we will follow.</p>
<p>While we do not have time to get into the philosophy of science in this class, if you are interested, read up on <a href="https://plato.stanford.edu/entries/popper/">Karl Popper and falsification</a>.</p>
<p><br></p>
<div class="figure">
<img src="Images/popper.png" alt="Figure 1 Karl Popper and falsification" />
<p class="caption"><strong>Figure 1</strong> Karl Popper and falsification</p>
</div>
<p>(<a href="https://xkcd.com/2078/" class="uri">https://xkcd.com/2078/</a>)</p>
<p><br></p>
<p>This is the approach that we follow with hypothesis testing – instead of showing that our hypothesis is correct, we want to demonstrate that the hypothesis that is <em>NOT</em> ours is <em>NOT</em> correct. How do we do this?</p>
<p><br></p>
<div id="the-null-hypothesis" class="section level3">
<h3><span class="header-section-number">6.1.1</span> The null hypothesis</h3>
<p>We do this with something called a <strong>null hypothesis</strong>. The null hypothesis can be seen as the opposite of our hypothesis – what is expected if our hypothesis were <em>not true</em> in the population. When we carry out our hypothesis testing, we aim to reject the <strong>null hypothesis</strong>.</p>
<p>Our hypothesis (<span class="math inline">\(H_A\)</span>) is considered the <em>alternative</em> (hence the ‘A’) of the null hypothesis (<span class="math inline">\(H_0\)</span>). Returning to our intervention programme example, <span class="math inline">\(H_A\)</span> was: the intervention reduces reoffending. The <span class="math inline">\(H_0\)</span>, however, will state that <em>there is no relationship between the intervention and reoffending</em>. In other words, the new intervention programme will not reduce reoffending and, therefore, there will be no difference in reoffending rates between participants in the control and treatment groups.</p>
<p>We test the null hypothesis and we will either <em>reject</em> or <em>fail to reject</em> it. If we reject our null hypothesis, that is good, because it seems that, as far as we can tell, there is a relationship between our variables (intervention and reoffending), or in other words, a difference between control and treatment groups in reoffending. Another way of understanding this is that we had tried to disprove that there was a relationship between the variables and were unable. Thus, we can continue to believe the new intervention has an effect on reoffending, and we can continue asking funders to support it in good conscience.</p>
<p>If, however, we fail to reject <span class="math inline">\(H_0\)</span>, this means we managed to disprove <span class="math inline">\(H_A\)</span>. Applied to the example of the new intervention for at-risk Manchester youth, we should stop asking for funding to support this intervention because we cannot claim that it works in reducing reoffending.</p>
<p>Notice that at no point did we say ‘we proved this works’, as we cannot actually do this. All we can do is disprove or fail to disprove. Someone else can come along and try to disprove. This is science. If this someone obtains the same results as we have, we can say that <em>our results replicate</em>. If different results were obtained, then our findings come into question. This may sound familiar from last semester. If you are interested in the sordid misadventures of scientific (primarily psychological) research, <a href="https://www.penguin.co.uk/books/111/1117290/science-fictions/9781847925657.html">Science Fictions by Stuart Ritchie</a> is a recommended read.</p>
<p><br></p>
<div id="activity-1-example-hypotheses" class="section level4">
<h4><span class="header-section-number">6.1.1.1</span> Activity 1: Example Hypotheses</h4>
<p>In this activity, let us look at some (alternative) hypotheses and then some null hypotheses. We will then construct some of our own.</p>
<p>First, we consider our previous example of youth reoffending and formalise our hypotheses.</p>
<p>Our alternative hypothesis could be formalised as:
<br></p>
<ul>
<li><span class="math inline">\(H_A\)</span>: There is a difference in reoffending rates between those who participated in the new intervention programme and those who did not participate in said programme.</li>
</ul>
<p><br>
In contrast, our null hypothesis should be stated as:
<br></p>
<ul>
<li><span class="math inline">\(H_0\)</span>: There is no difference in reoffending rates between those who participated and those who did not participate in the new intervention programme</li>
</ul>
<p><br></p>
<p>What about the research question on how low self-control is predictive of later criminal behaviour?</p>
<p>Here is the alternative hypothesis:
<br></p>
<ul>
<li><span class="math inline">\(H_A\)</span>: There is a relationship between engaging in criminal behaviour and scoring low on assessments of self-control.</li>
</ul>
<p><br>
Now, what do you think the accompanying null hypothesis might be? Think about this and type it out in the google docs.</p>
<p>And, finally, we considered whether adverts on reporting sexual harassment on public transport will increase awareness. If we wanted to test this, what would our <span class="math inline">\(H_A\)</span> look like? What about our <span class="math inline">\(H_0\)</span>?</p>
<p><br></p>
<p>When we make predictions, we always state both <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_A\)</span>. Doing so communicates the specific aim of our statistical analyses (e.g., to disprove that there is no difference in levels of reoffending) and helps guide us in selecting appropriate analyses to use on our sample as well as what sort of conclusions can be made from them about our population of interest.</p>
<p><br>
<br></p>
<hr />
</div>
</div>
<div id="directional-hypotheses" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Directional hypotheses</h3>
<p>When we are formulating our hypothesis, we can also choose whether it is a <strong>directional hypothesis</strong> or a <strong>non-directional hypothesis</strong>.</p>
<p>A directional hypothesis is where you specify the direction of the relationship expected, whereas a non-directional hypothesis is where you are only interested in whether there is a relationship between variables (i.e., any difference between groups).</p>
<p>The new intervention on reoffending example is a non-directional hypothesis because we do not state specifically whether we want reoffending rates to be lower or higher in each group of at-risk young people. Here, again, is the alternative hypothesis:
<br></p>
<ul>
<li><span class="math inline">\(H_A\)</span>: There is a difference in reoffending rates between those who participated in the new intervention programme and those who did not participate in said programme.</li>
</ul>
<p><br></p>
<p>In contrast, our null hypothesis also only refers to a difference between the two groups:
<br></p>
<ul>
<li><span class="math inline">\(H_0\)</span>: There is no difference in reoffending rates between those who participated and those who did not participate in the new intervention programme
<br></li>
</ul>
<p>With this, if we observe <em>any</em> difference between the two groups, we reject our null hypothesis. Previously, we mentioned that this result was great because it meant our intervention worked, so we can apply for more funding. But we did not say anything about the <em>direction</em> of this relationship – we stated that there was a difference but did not account for the possibility that it could mean there was actually more reoffending among those who participated in the intervention than those who did not!</p>
<p><br></p>
<div id="activity-2-applying-knowledge-on-directional-hypotheses" class="section level4">
<h4><span class="header-section-number">6.1.2.1</span> Activity 2: Applying knowledge on directional hypotheses</h4>
<p>Think what might be a <em>directional</em> hypothesis for our new-intervention-to-reduce-reoffending example. Discuss this in your chatty group and type in your google docs the directional <span class="math inline">\(H_A\)</span> and <span class="math inline">\(H_0\)</span>. We will revisit this later.</p>
<p><br>
<br></p>
<hr />
</div>
</div>
</div>
<div id="todays-3-3" class="section level2">
<h2><span class="header-section-number">6.2</span> Today’s 3</h2>
<p>To understand hypotheses in action, we learn three substantive concepts today: <strong>statistical significance</strong>, <strong>binominal test</strong>, and <strong>single-sample significance tests</strong>.<br />
<br></p>
<div id="statistical-significance" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Statistical Significance</h3>
<p>When testing whether there is a relationship between two variables (e.g., intervention and reoffending), you may hear the term <strong>statistical significance</strong>. You may have read this in criminology articles in your other classes. You might read something like:</p>
<p><br></p>
<blockquote>
<p>‘There is a statistically significant relationship between the treatment of a new intervention and reoffending rates among at-risk young people.’</p>
</blockquote>
<p><br></p>
<p>What is meant by statistical significance? It is a misleading term because it seems to mean that the result is <em>significant</em> or <em>important</em> in some way, but that is incorrect. When we test for statistical significance, we are simply testing to see whether we can confidently generalise from our sample to our population.</p>
<p>Statistical significance also does not tell us about how big any difference in reoffending is between our two groups, for example. All it tells us is whether <em>we are confident</em> that the difference observed in our sample can be generalised to the population. What is meant by ‘we are confident’? Confidence is key in hypothesis testing. If we reject the null hypothesis, we want to be confident that it is actually false.</p>
<p>In criminology, and across the social sciences, it is common to want to be at least 95% confident in our result. (Recall our 95% confidence intervals recently learned.) While 95% sounds steep, keep in mind that this implies that we are willing to be wrong 5% of the time. If our study of reoffending, for example, is repeatedly replicated, we expect about 1 in 20 of the results to reach incorrect conclusions.</p>
<p>Why are we willing to accept error? The reason is we cannot be 100% confident; we usually do not have information from the entire population, so find ourselves trying to decide whether our null hypothesis is false without being so sure of the true result in the population.</p>
<p><br></p>
<div id="type-1-error" class="section level4">
<h4><span class="header-section-number">6.2.1.1</span> Type 1 error</h4>
<p>Because of this uncertainty, we need to be wary of <strong>type 1 error</strong>. This error, known also as a <em>false positive</em>, occurs when we reject the null hypothesis when it is actually true. In addition, there is also <strong>type 2 error</strong>, <em>a false negative</em>, which occurs when we fail to reject the null hypothesis even though it is actually false. The image below might help understand these errors:</p>
<p><br></p>
<div class="figure">
<img src="Images/errors.jpg" alt="Figure 6.1 Type 1 and Type 2 errors" />
<p class="caption"><strong>Figure 6.1</strong> Type 1 and Type 2 errors</p>
</div>
<p><br></p>
<!-- We mentioned earlier that you start your study with clarifying and formalising your hypotheses. Hypotheses are created before the researcher collects outcome data for the study and conducts any analysis. This is good practice and ethical as well, because if the hypotheses are stated after data has been collected and analysed, then the researcher may be tempted to change the hypotheses, so will dishonestly influence the tests of statistical significance. Also, this affects Type 1 error because we are increasing its likelihood through bad practice – we want to leave that 5% of getting it wrong to chance only. -->
<p>In testing for statistical significance, we are concerned with rejecting the null hypothesis with high confidence that it is actually false. For this, we will need to identify the risk of making a type 1 error and hope that the risk is as small as possible in a <strong>test of statistical significance</strong>.</p>
<p>How to calculate this risk of type 1 error? We do this by testing to see if the probability of the null hypothesis being true is less than the level of type 1 error specified.</p>
<p><br></p>
</div>
<div id="significance-level" class="section level4">
<h4><span class="header-section-number">6.2.1.2</span> Significance level</h4>
<p>The level specified is called the <strong>significance level</strong> and is denoted by alpha (α). In the social sciences, it is usually set at α = 0.05 to indicate that we want to be 95% confident in our rejection of the null hypothesis. We then use this value as a cut-off value. If the probability of the null hypothesis is less than α = 0.05, for example, then we can reject it. If, however, the probability is greater than α = 0.05, then we have failed to reject the null hypothesis.</p>
<p>The probability obtained is the <strong>p-value</strong>, short for probability value, and it tells us how likely we are to observe that certain result or effect which we found in our sample if the null hypothesis were true.
<!-- That is why if the probability is less then 5%, then it is unlikely to happen.  --></p>
<p>Again, (like the ‘disprove or fail to disprove’ the null hypothesis), the terminology is important here: we can only say we ‘reject’ or ‘fail to reject’ the null hypothesis; we cannot say we ‘accept’ the null hypothesis because testing for statistical significance is not about finding out if the null hypothesis is correct.</p>
<p>Let us return to the intervention for reoffending example: we find that one year after allocating the young people into treatment and control groups, 10 out of the 50 young people in the treatment group went on to reoffend whereas, in the control group, 28 out of the 50 went on to reoffend.</p>
<p>When we hypothesis test, we will look for whether this difference in reoffending numbers is <em>statistically significant</em> – that is, the probability of this between-group difference occurring when our null hypothesis – that the new intervention has no effect – is true. If we find this probability to be small (less than our cut-off value of <span class="math inline">\(\alpha = 0.05\)</span>), we <em>reject the null hypothesis</em>. If, however, we find the probability to be larger than our cut-off value of <span class="math inline">\(\alpha = 0.05\)</span>, then we <em>fail to reject</em> our null hypothesis.</p>
<p>Now, how can we calculate this probability value? We learn this in the next section.</p>
<!-- Another important point: lately, there has been substantial [calls to get rid of p-values and statistical significance](https://www.vox.com/latest-news/2019/3/22/18275913/statistical-significance-p-values-explained). The problem is that the p-value is often misunderstood and even misused. It has come to be misinterpreted as either the study worked (a good study) or did not work (a bad study). **That is why including confidence intervals is good practice**. Even though the practice of relying on p-values is controversial, we learn about statistical significance in this course unit because many studies still use it. Understanding what it actually is will prevent misinterpretation.  -->
<p><br></p>
<hr />
</div>
</div>
<div id="a-binomial-test" class="section level3">
<h3><span class="header-section-number">6.2.2</span> A Binomial Test</h3>
<p>Now that we have established what is statistical significance, we must identify the most appropriate test for statistical significance. Selecting an appropriate test depends on a number of assumptions. The remainder of the course unit will introduce you to a number of these tests. For today, we learn about specific hypothesis tests using the binomial distribution and then the normal distribution, and each have their own set of assumptions. We illustrate hypothesis testing using the binomial distribution.</p>
<div id="activity-3-distributions" class="section level4">
<h4><span class="header-section-number">6.2.2.1</span> Activity 3: Distributions</h4>
<p>In the previous week we spoke a lot about the normal distribution. We also mentioned that the sampling distribution of your sample statistic (eg mean) will always follow a normal distribution, even if your data follow different distributions. And your data often will! For example, count data often follows a <a href="">Poisson distribution</a>. And here, in the case of our re-offending of young people study, we are looking at a <a href="">Binomial</a> distribution. Binary variables (when there are only two outcomes, which are mutually exclusive - remember the illustrations where the animals were either extinct or not) may follow a Binomial distribution. We can code binary data as 0s and 1s, where 1s are our event (sometimes called successes) and 0s are when you don’t observe the event (sometimes called failures).</p>
<p>In the case of our data on re-offending, we could consider re-offending an event (1) while not having re-offended at the 1-year follow up the absence of this event (0). You can see why we don’t always want to call the event the “success”, you might get funny looks if you say that the young people re-offending is a success…!</p>
<p>So in any case, let’s get some fake data up again for our young people. We use the <code>data.frame()</code> function to build a data frame. We will give each young person an id of 1 to 100 (it’s an anonymous study), and then we will assign 50 to treatment and 50 to control (I say assign, here we are making the data up!!!) and then we assign values for the binary varaible of whether they had re-offended or not by the time of our 1-year follow-up.</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb318-1" title="1">young_people &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</a>
<a class="sourceLine" id="cb318-2" title="2">  <span class="dt">id =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>), </a>
<a class="sourceLine" id="cb318-3" title="3">  <span class="dt">group =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;treatment&quot;</span>, <span class="dv">50</span>), <span class="kw">rep</span>(<span class="st">&quot;control&quot;</span>, <span class="dv">50</span>)), </a>
<a class="sourceLine" id="cb318-4" title="4">  <span class="dt">reoffended =</span>  <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>), <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">40</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">28</span>), <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">22</span>))</a>
<a class="sourceLine" id="cb318-5" title="5">)</a></code></pre></div>
<p>Let’s see the distribution of our outcome variable, re-offending:</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb319-1" title="1"><span class="kw">library</span>(ggplot2)</a></code></pre></div>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 3.6.3</code></pre>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb321-1" title="1"><span class="kw">ggplot</span>(young_people, <span class="kw">aes</span>(<span class="dt">x =</span> reoffended)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb321-2" title="2"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">2</span>, <span class="dt">fill =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb321-3" title="3"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb321-4" title="4"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb321-5" title="5"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Re-offending at 1-year follow up&quot;</span>)</a></code></pre></div>
<p><img src="06-hypotheses_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>We can see that overall there is quite a high count of re-offending in our follow-up.</p>
<p>But what we are interested in is probability to have see the number of successes (re-offences) in our outcome. What does this look like for our binomial distribution? Remember that we are looking at a probability distribution, which tells us what is the probability that we get a certain number of young people reoffending? We have 100 young people, what is the probability of having <span class="math inline">\(k\)</span> number of them re-offend? (i.e. <span class="math inline">\(P(X=k)\)</span>). For our binomial distribution, we calculate the probability of observing <span class="math inline">\(k\)</span> young people who re-offended for each possible <span class="math inline">\(k\)</span>. So for example, we want to calculate what is the probability that exactly one young person re-offended. Then that exactly two young people re-offended. Then that exactly three young people re-offended. And so on…!</p>
<p>So what is the probability for each one of these outcomes? We use the equation below to calculate this:</p>
<p><span class="math inline">\(Binomial(n,k,p) = C(n,k) * p^k * (1-p)^{n-k}\)</span></p>
<p>Where <span class="math inline">\(C(n,k)\)</span> refers to all the possible combinations in which you can have <span class="math inline">\(k\)</span> people re-offend in our sample of <span class="math inline">\(n\)</span>. So for example for the probability that 38 people re-offended out of our sample of 100, we calculate this <span class="math inline">\(C(n,k) = {n!}/{(n-k)!}\)</span> as <span class="math inline">\(C(100,38) = {100!}/{100!*(100-38)!}\)</span>. <code>!</code> means <code>factorial</code>, which in R you can caluclate with the <code>factorial()</code> function.</p>
<p>So</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb322-1" title="1"><span class="kw">factorial</span>(<span class="dv">100</span>)<span class="op">/</span><span class="kw">factorial</span>(<span class="dv">100-38</span>)</a></code></pre></div>
<pre><code>## [1] 2.965564e+72</code></pre>
<p>You can see there are many many different ways in which we can choose 38 re-offenders.</p>
<p>The last thing left to plug into the equation is <code>p</code>, which is the probability of an outcome. Assuming that the re-offending is as likely an outcome as not re-offending, this value is 0.5 (as there are only two possible outcomes!).</p>
<p>So binging it all together, the probability that we get exactly one re-offence in our data is:</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb324-1" title="1">(<span class="kw">factorial</span>(<span class="dv">100</span>)<span class="op">/</span>(<span class="kw">factorial</span>(<span class="dv">100</span>)<span class="op">*</span><span class="kw">factorial</span>(<span class="dv">100-38</span>)))<span class="op">*</span>( <span class="fl">0.5</span><span class="op">^</span><span class="dv">38</span>) <span class="op">*</span><span class="st"> </span>((<span class="dv">1</span><span class="fl">-0.5</span>)<span class="op">^</span>(<span class="dv">100-38</span>))</a></code></pre></div>
<pre><code>## [1] 2.50671e-116</code></pre>
<p>Now we can use some pseudo-random numbers to simulate what our binomial probability distribution will look like. I use simulation of 1000 replications of this study, with sample sizes of 100 young people each, something like we did last week, but I won’t cover how to do this, as it’s not important for you here, but I’ll show you the output anyway:</p>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 3.6.3</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<p><img src="06-hypotheses_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>You can see that if generally in the population without any treatment we assume it’s about 50/50 whether a young person re-offends, these are the sort of re-offending outcomes we can expect to observe. We can see our sample overall (both ground together) are on the left tail of this distribution. Let’s move on now to how we can use this for hypothesis testing.</p>
</div>
<div id="activity-4-making-assumptions" class="section level4">
<h4><span class="header-section-number">6.2.2.2</span> Activity 4: Making Assumptions</h4>
<p>All the ways in which we will be learning hypothesis testing rely on certain assumptions about your data. If these assumptions are violated, then the tests may not be as effective as we’d like, and can even result in erroneous conclusions. Therefore it is very important to consider the assumptions, and address whether these are <em>met</em> or <em>violated</em> by our data.</p>
<p>Hypothesis testing using the binomial distribution have the following assumptions:</p>
<ol style="list-style-type: decimal">
<li><p><em>Level of measurement:</em> the variable is binary, meaning it measures only two possible categories.</p></li>
<li><p><em>Shape of the population distribution:</em> None</p></li>
<li><p><em>Sample:</em> high external validity</p></li>
<li><p><em>Hypothesis:</em> stated before collection and analysis of data</p></li>
</ol>
<p>How can we check that these assumptions are met?</p>
<ul>
<li>Well the first one asks about the <em>level of measurement</em> of our outcome variable. Since that is a binary variable (for each young person, we know whether they re-offended (1) or not (0)), this assumption is <em>met</em>.</li>
<li>The second assumption, about the shape of the distribution, the test makes no assumptions. Therefore there is nothing to check!</li>
<li>The third question asks about our sample. Are they likely to be representative of the population? This is usually best assessed by looking at the sampling strategy - e.g. are they selected using some random (probability) sampling technique? While here we are creating fake data, in real-world studies you will hear about the sampling, and how it ensures this validity.</li>
<li>Finally the fourth question asks us whether we stated our hypothesis before collecting our data. In this case, we did, we formalised our <span class="math inline">\(H_A\)</span> and <span class="math inline">\(H_0\)</span> before collecting our data.</li>
</ul>
</div>
<div id="activity-5-statistical-significance-with-proportions-test" class="section level4">
<h4><span class="header-section-number">6.2.2.3</span> Activity 5: Statistical significance with proportions test</h4>
<p>Now that we have addressed the assumptions, let’s look at our data again. The sample comprises 100 at-risk young people who are randomly assigned to two groups: 50 to a treatment group that receives the intervention that aims to prevent them from committing future offences and 50 to the control group that receives no intervention. We evaluate this programme to see if it works and if it can be generalised to all at-risk youth in Manchester, by checking in 1 year on as a follow-up, to see whether the young people re-offended at different proportions in the two groups. As the outcome has only two options – success and failure – we rely on the <strong>binomial distribution</strong>.</p>
<p>In <code>R</code>, we run the <code>prop.test()</code> function to test the null hypothesis that the proportions, or probabilities of success, are the same or equal in several groups.</p>
<p>Let’s look at the differences in re-offending between the two groups We can use the <code>facet_wrap()</code> function in <code>ggplot2</code> to look at the two groups side by side:</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb330-1" title="1"><span class="kw">ggplot</span>(young_people, <span class="kw">aes</span>(<span class="dt">x =</span> reoffended)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb330-2" title="2"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">2</span>, <span class="dt">fill =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb330-3" title="3"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb330-4" title="4"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb330-5" title="5"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Re-offending at 1-year follow up&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb330-6" title="6"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>group)</a></code></pre></div>
<p><img src="06-hypotheses_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Wow we see very different proportions in the two groups!</p>
<p>Let’s look at the number of people who re-offended in each group.</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb331-1" title="1">young_people <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(group, reoffended) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>()</a></code></pre></div>
<pre><code>## # A tibble: 4 x 3
## # Groups:   group, reoffended [4]
##   group     reoffended     n
##   &lt;fct&gt;          &lt;dbl&gt; &lt;int&gt;
## 1 control            0    22
## 2 control            1    28
## 3 treatment          0    40
## 4 treatment          1    10</code></pre>
<p>We find that in the treatment group, 10 out of the 50 went on to reoffend whereas, in the control group, 28 out of the 50 went on to reoffend.</p>
<p>We could stop here and conclude, ‘Yes, there is a difference between groups, and by golly, the intervention works.’ But remember that chance, or random variation, is inherent in all phenomena, so this observation could just be a mere fluke. That is why we conduct a test of statistical significance. This one is called a ‘two-sample proportion test’. So like mentioned we use the <code>prop.test()</code> function, and we need to give two <em>pairs</em> of values, <code>x</code> and <code>n</code>. For the <code>x</code> value, we need to specify the number of successes (1s) in each group. We have 10 successes (number of young people who have re-offended…. you can see why “success” is an awkward word to use for many criminology research…!) in the treatment group, and 28 in the control. So here we put them together as <code>c(10, 28)</code>. The second value pair, <code>n</code>, refers to the sample sizes of each group. Here we had the same number (50) in each group so the value is <code>c(50,50)</code>. Bring it together like so:</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb333-1" title="1"><span class="co"># The first concatenate (c () ) contains the numbers that went onto reoffend</span></a>
<a class="sourceLine" id="cb333-2" title="2"><span class="co"># The second concatenate contains the total numbers in each group</span></a>
<a class="sourceLine" id="cb333-3" title="3"><span class="kw">prop.test</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">28</span>), <span class="dt">n =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">50</span>))</a></code></pre></div>
<pre><code>## 
##  2-sample test for equality of proportions with continuity correction
## 
## data:  c(10, 28) out of c(50, 50)
## X-squared = 12.267, df = 1, p-value = 0.0004611
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.5567014 -0.1632986
## sample estimates:
## prop 1 prop 2 
##   0.20   0.56</code></pre>
<p>The output is a little ugly, but you can refer to the help documentation for more detail on the output by typing <code>?prop.test</code>.</p>
<p>You can see there are some points of interest in there for us. We can extract them individually by saving the results into a new object. Let’s call this <code>reoff_results</code>:</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb335-1" title="1">reoff_results &lt;-<span class="st"> </span><span class="kw">prop.test</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">28</span>), <span class="dt">n =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">50</span>))</a></code></pre></div>
<p>Then we can extract this from our new object <code>reoff_results</code> the same way we refer to variables in dataframes, by using the <code>$</code> operator.</p>
<p>Let us focus on interpreting these results:</p>
<ul>
<li><strong>P-value</strong>: probability of observing this difference in proportions given the null hypothesis is true. To extract this value we need <code>$p.value</code> and then check – is it less than α = 0.05 ?</li>
</ul>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb336-1" title="1">reoff_results<span class="op">$</span>p.value</a></code></pre></div>
<pre><code>## [1] 0.0004611492</code></pre>
<ul>
<li><strong>Alternative hypothesis</strong>: although we should specify the direction of the hypothesis before even collecting our data, R reminds us of our choices here. Since let’s say initially we expect between-group differences in either direction so it is <strong>non-directional</strong> or <strong>two-sided</strong>.</li>
</ul>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb338-1" title="1">reoff_results<span class="op">$</span>alternative</a></code></pre></div>
<pre><code>## [1] &quot;two.sided&quot;</code></pre>
<ul>
<li><strong>The estimate</strong>: this gives you the proportion of successess attributed to each group – 20% in one group (10/ 50) (prop1) and 56% in the other (28/ 50) (prop2)</li>
</ul>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb340-1" title="1">reoff_results<span class="op">$</span>estimate</a></code></pre></div>
<pre><code>## prop 1 prop 2 
##   0.20   0.56</code></pre>
<p><strong>So how do you interpret these numbers?</strong></p>
<p>The p-value is less than the specified <span class="math inline">\(\alpha\)</span> = 0.05, so we can <em>reject our null hypothesis of no difference</em> say that the difference in re-offending between the two groups is statistically significant. We have evidence to reject the null hypothesis that no difference in re-offending exists between the treatment and control groups. This suggests that <em>something</em> is happening because of the intervention, but we are not sure what. We could now turn to look at the proportions in each group, and state that we can see fewer proportion of young people who went through the treatment re-offended than those in the control, who did not receive the treatment. But what if we wanted</p>
</div>
<div id="activity-6-directional-tests" class="section level4">
<h4><span class="header-section-number">6.2.2.4</span> Activity 6: Directional tests</h4>
<p>Now, what about if we want a directional hypothesis? For example, we expect that re-offending reduces in the treatment group compared to the control group. In this case, we think that the treatment group will have <em>less</em> re-offending, and this becomes our <span class="math inline">\(H_A\)</span> which we are testing. As our hypothesis has changed, the test we use has changed. Remember the assumptions of our test, that we have specified our hypotheses in advance? This is why this is important! In reality we will only run one hypothesis test. Here we just demonstrate multiple for you to learn!</p>
<p>Okay, so how to test for a one-tailed (one-sided) <em>directional</em> hypothesis? Well we can specify within the <code>prop.test()</code> function what we want our <code>aternative</code> hypothesis to be.</p>
<p>By default, <code>prop.test()</code> function will preform a “two.sided” test (non-directional hypothesis). This is why we did not have to specify this parameter above (although we were reminded with the <code>$alternative</code> output of our results!). To specify, we can choose which way we think the direction will go. We can choose “less” or “greater” depending on whether we think that re-offending in our treatment group will be less than in the control, or greater than in the control. Ideally, we want our treatment to <em>reduce</em> re-offending, not increase it (although remember the <em>scared straight</em> interventions we discussed last semester??), so we will choose “less” here:</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb342-1" title="1"><span class="co"># We add ‘alternative=’ and specify ‘less’ to indicate we expect the treatment group to have a smaller probability of reoffending than the control</span></a>
<a class="sourceLine" id="cb342-2" title="2">reoff_directional_results &lt;-<span class="st"> </span><span class="kw">prop.test</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">28</span>), <span class="dt">n =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">50</span>), <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>)</a></code></pre></div>
<p>So what are the results now? Well first let’s check the <span class="math inline">\(H_A\)</span> we just tested with the test we just performed:</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb343-1" title="1">reoff_directional_results<span class="op">$</span>alternative</a></code></pre></div>
<pre><code>## [1] &quot;less&quot;</code></pre>
<p>We see the <span class="math inline">\(H_A\)</span> we tested is that the treatment group has re-offended (succeeded??) <em>less</em> than the control group.</p>
<p>Great! Does this change our conclusions?</p>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb345-1" title="1">reoff_directional_results<span class="op">$</span>p.value</a></code></pre></div>
<pre><code>## [1] 0.0002305746</code></pre>
<p>Doesn’t seem so. Again, the p-value is less than <span class="math inline">\(\alpha\)</span> = 0.05, so we have sufficient indication to reject our null hypothesis. In other words, there is evidence to suggest that the at-risk youth in the treatment did offend less than in the control group due to the intervention, and this finding is statistically significant – we can generalise this result to the population which they represent.</p>
<p>Now if, for example, we found out that the therapist hired to deliver the intervention was a fraud, we may be worried the treatment group did worse than the control group. We then would expect a directional hypothesis where reoffending is higher in the treatment group than that of the control. We run the two-sample proportion test again, but with a slight difference to the direction:</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb347-1" title="1"><span class="co"># We specify ‘greater’ following ‘alternative’ to indicate our expected direction for the treatment group relative to the control group</span></a>
<a class="sourceLine" id="cb347-2" title="2">reoff_greater_results&lt;-<span class="st"> </span><span class="kw">prop.test</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">28</span>), <span class="dt">n =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">50</span>), <span class="dt">alternative =</span> <span class="st">&quot;greater&quot;</span>)</a></code></pre></div>
<p>Let’s check the p-value</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb348-1" title="1">reoff_greater_results<span class="op">$</span>p.value</a></code></pre></div>
<pre><code>## [1] 0.9997694</code></pre>
<p>The p-value is greater than the specified 0.05, meaning that we have failed to reject the null hypothesis, and we do not have adequate evidence to support our hypothesis that our intervention <em>increases</em> re-offending.</p>
<p><strong>NOTE:: </strong>With this example, we have committed some bad practice: we did multiple hypothesis tests. This is a no-no: stick to one hypothesis and test that. Our purpose here, however, was to demonstrate how to run the binomial test. Recall that it is important to state your hypotheses before you collect and analyse your data.</p>
</div>
<div id="activity-7-confidence-intervals" class="section level4">
<h4><span class="header-section-number">6.2.2.5</span> Activity 7: Confidence Intervals</h4>
<p>Last week we introduced Confidence Intervals. Including confidence intervals (CIs) is good practice, and it is possible to create them for binomial proportions. For example, we would like to build CIs around the proportion of the outcome for each group. We use the <code>BinomCI ()</code> function in the <code>DescTools</code> package to do so. We specify 3 parameters, (1) the number of successes (re-offenders), the sample size (50 for each group), and the confidence level (let’s stick with 95%):</p>
<p>First for the treatment group:</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb350-1" title="1"><span class="kw">library</span>(DescTools)</a></code></pre></div>
<pre><code>## Warning: package &#39;DescTools&#39; was built under R version 3.6.3</code></pre>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb352-1" title="1"><span class="co"># CIs for treatment group where 10 reoffended</span></a>
<a class="sourceLine" id="cb352-2" title="2"><span class="kw">BinomCI</span>(<span class="dv">10</span>, <span class="dv">50</span>, <span class="dt">conf.level =</span> <span class="fl">0.95</span>)</a></code></pre></div>
<pre><code>##      est    lwr.ci    upr.ci
## [1,] 0.2 0.1124375 0.3303711</code></pre>
<p>Then for the treatment:</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb354-1" title="1"><span class="co"># CIs for control group where 28 reoffended</span></a>
<a class="sourceLine" id="cb354-2" title="2"></a>
<a class="sourceLine" id="cb354-3" title="3"><span class="kw">BinomCI</span>(<span class="dv">28</span>, <span class="dv">50</span>, <span class="dt">conf.level =</span> <span class="fl">0.95</span>)</a></code></pre></div>
<pre><code>##       est    lwr.ci   upr.ci
## [1,] 0.56 0.4230603 0.688378</code></pre>
<p>In the CI for the treatment group, 11 to 33% of young people exposed to the intervention will reoffend, whereas the CI for the control group indicates that 42 to 69% of the young people not exposed to the intervention will reoffend. This seems like a large difference. To get a better understanding, we visualise this using <code>ggplot</code>:</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb356-1" title="1"><span class="co"># Taking the previous coding and placing them in objects</span></a>
<a class="sourceLine" id="cb356-2" title="2">treatment_group &lt;-<span class="st"> </span><span class="kw">BinomCI</span>(<span class="dv">10</span>, <span class="dv">50</span>, <span class="dt">conf.level =</span> <span class="fl">0.95</span>) </a>
<a class="sourceLine" id="cb356-3" title="3">control_group &lt;-<span class="st"> </span><span class="kw">BinomCI</span>(<span class="dv">28</span>, <span class="dv">50</span>, <span class="dt">conf.level =</span> <span class="fl">0.95</span>)</a>
<a class="sourceLine" id="cb356-4" title="4"></a>
<a class="sourceLine" id="cb356-5" title="5"><span class="co"># Creating two error bar layers, one for each group</span></a>
<a class="sourceLine" id="cb356-6" title="6"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb356-7" title="7"><span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">ymin =</span> treatment_group[<span class="dv">2</span>], <span class="dt">ymax =</span> treatment_group[<span class="dv">3</span>], <span class="dt">x =</span> <span class="st">&quot;treatment&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;treatment&quot;</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb356-8" title="8"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> treatment_group[<span class="dv">1</span>], <span class="dt">x =</span> <span class="st">&quot;treatment&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;treatment&quot;</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_errorbar</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">ymin =</span> control_group[<span class="dv">2</span>], <span class="dt">ymax =</span> control_group[<span class="dv">3</span>], <span class="dt">x =</span> <span class="st">&quot;control&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;control&quot;</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb356-9" title="9"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> control_group[<span class="dv">1</span>], <span class="dt">x =</span> <span class="st">&quot;control&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;control&quot;</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb356-10" title="10"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Group&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb356-11" title="11"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Proportion who reoffended at follow-up&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb356-12" title="12"><span class="st">  </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<p><img src="06-hypotheses_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Visualising our results, we see further support that the intervention reduces reoffending: the confidence intervals for each group do not overlap and the proportion for the control group is lower than that of the treatment group. When the CIs between groups do not overlap, this is good because it indicates that the two groups likely come from two different populations.</p>
<hr />
</div>
</div>
<div id="single-sample-significance-tests" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Single-sample significance tests</h3>
<p>For this section, we learn about hypothesis tests that use the <em>normal distribution</em>.</p>
<p>Remember we’re starting with our assumptions. Hypothesis testing using the normal distribution have the following assumptions:</p>
<ol style="list-style-type: decimal">
<li><p><em>Level of measurement:</em> the variable is interval or ratio level</p></li>
<li><p><em>Shape of the population distribution:</em> normal distribution</p></li>
<li><p><em>Sample:</em> high external validity</p></li>
<li><p><em>Hypothesis:</em> stated before collection and analysis of data</p></li>
</ol>
<p>Unlike the binominal test, which compared groups, we will be comparing a single group – our sample – to the population. This may sound strange because we have learned that information about the population is rare, so we must make do with uncertainty. In some cases, however, we may know the population parameter and these tests can be used. When comparing our sample to a known population, we use the z- distribution; if we have to compare with an unknown population, we use the t-distribution. The z- and t- distributions are types of normal distributions.</p>
<p>The normal distribution has some predictable characteristics about it. One is that half of the distribution will always be below the mean, and the other half will be above the mean. We demonstrate this by creating a synthetic data of 1.5 million US prisoner IQ scores, drawn from a population that is normally distributed (<span class="math inline">\(\mu\)</span> = 100; SD = 15). We then test whether half of our population have an IQ above the mean. We introduce two new functions: <code>which()</code> to select a subset of prisoners who have an IQ of 100 + and <code>nrow()</code>, which divides the number of prisoners with an IQ of 100+ by the total number of prisoners:</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb357-1" title="1"><span class="co"># Make synthetic data which includes the variables ‘prisoner_id’ and ‘IQ’</span></a>
<a class="sourceLine" id="cb357-2" title="2"><span class="co"># ‘prisoner_id’ has 1 to 1.5 million IDs while ‘IQ’ has scores generated by ‘rnorm’ function </span></a>
<a class="sourceLine" id="cb357-3" title="3"><span class="co"># Place data frame in object called ‘prisoner_iq’</span></a>
<a class="sourceLine" id="cb357-4" title="4">prisoner_iq &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">prisoner_id =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1500000</span>, <span class="dt">IQ =</span> <span class="kw">round</span>(<span class="kw">rnorm</span>(<span class="dv">1500000</span>, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="dv">15</span>), <span class="dv">0</span>)) </a>
<a class="sourceLine" id="cb357-5" title="5"></a>
<a class="sourceLine" id="cb357-6" title="6"><span class="co"># Using ‘which’ function to make subset of prisoners with IQ above 100</span></a>
<a class="sourceLine" id="cb357-7" title="7"><span class="co"># ‘which’ is to the left of the ‘,’ at the end of code to specify that we are selecting rows</span></a>
<a class="sourceLine" id="cb357-8" title="8"><span class="co"># Place subset in object called ‘iq_over_100’</span></a>
<a class="sourceLine" id="cb357-9" title="9">iq_over_<span class="dv">100</span> &lt;-<span class="st"> </span>prisoner_iq <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(IQ <span class="op">&gt;</span><span class="st"> </span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb357-10" title="10"></a>
<a class="sourceLine" id="cb357-11" title="11"><span class="co"># Divide ‘iq_over_100’ by total number of prisoner IQ scores</span></a>
<a class="sourceLine" id="cb357-12" title="12"><span class="kw">nrow</span>(iq_over_<span class="dv">100</span>)<span class="op">/</span><span class="kw">nrow</span>(prisoner_iq)</a></code></pre></div>
<pre><code>## [1] 0.4863087</code></pre>
<p>The result should be close to .50 indicating that half of the population will have an IQ higher than the mean. This illustrates a useful feature of the normal distribution: the percentage of cases between its mean and points at a measured distance are fixed. This is referred to as the standard deviation (SD) unit, and the <strong>z-score</strong> is used to represent it. Z-scores range from -4 standard deviations below the mean and +4 standard deviations above the mean.</p>
<div id="activity-8-calculating-a-z-score" class="section level4">
<h4><span class="header-section-number">6.2.3.1</span> Activity 8: Calculating a z-score</h4>
<p>This should all be sounding a bit familiar now. All the z-score does is express in standard deviations, how far away a particular observed value lies from the mean. The z score of any observed value can be calculated by subtracting the mean from the observation, and dividing by the standard deviation. Simply:</p>
<p><span class="math inline">\(z = \frac{x - \mu}{\sigma}\)</span></p>
<p>However, since R is nice to us, we can make it even simpler to create z-scores, we can use the function <code>scale()</code>. For the next example, we take the IQ of five prisoners and change the IQ of the first prisoner from 102 to 115 so that it is easy to show that this prisoner’s z-score is 1. The reason is the prisoner’s IQ score of 115 is one standard deviation above the population mean. (Remember: <span class="math inline">\(\mu\)</span> = 100; SD = 15):</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb359-1" title="1"><span class="co"># View the first 5 prisoner IQs</span></a>
<a class="sourceLine" id="cb359-2" title="2">prisoner_iq[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,] </a></code></pre></div>
<pre><code>##   prisoner_id  IQ
## 1           1 120
## 2           2 105
## 3           3 111
## 4           4  89
## 5           5  93</code></pre>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb361-1" title="1"><span class="co"># Change the IQ of prisoner #1 </span></a>
<a class="sourceLine" id="cb361-2" title="2">prisoner_iq<span class="op">$</span>IQ[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="dv">115</span></a>
<a class="sourceLine" id="cb361-3" title="3"></a>
<a class="sourceLine" id="cb361-4" title="4"><span class="co"># Create a variable storing z-scores of IQs </span></a>
<a class="sourceLine" id="cb361-5" title="5">prisoner_iq<span class="op">$</span>z_scoreIQ &lt;-<span class="st"> </span><span class="kw">scale</span>(prisoner_iq<span class="op">$</span>IQ) </a>
<a class="sourceLine" id="cb361-6" title="6"></a>
<a class="sourceLine" id="cb361-7" title="7"><span class="co"># Check to make sure prisoner #1 has a z-score around 1 </span></a>
<a class="sourceLine" id="cb361-8" title="8">prisoner_iq[<span class="dv">1</span>,]</a></code></pre></div>
<pre><code>##   prisoner_id  IQ z_scoreIQ
## 1           1 115  1.000122</code></pre>
<p>To show that this is the same z-score you would get with the formula above, go ahead and calculate <span class="math inline">\(z = \frac{x - \mu}{\sigma}\)</span>:</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb363-1" title="1">(<span class="dv">115</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(prisoner_iq<span class="op">$</span>IQ))<span class="op">/</span><span class="kw">sd</span>(prisoner_iq<span class="op">$</span>IQ)</a></code></pre></div>
<pre><code>## [1] 1.000122</code></pre>
<p>Same value!</p>
<p>Where the z-score becomes practical is illustrated in the following example: say if a probation officer is writing a report for a prisoner who is about to be up for parole. The prisoner has an IQ of 124. The officer wants to give a good idea of how this score compares to all other prisoners. An apt way of doing this is to state the proportion of prisoners who have lower IQs. This can be done using the <code>pnormGC()</code> function from the <code>tigerstats</code> package:</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb365-1" title="1"><span class="kw">library</span>(tigerstats)</a></code></pre></div>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb366-1" title="1"><span class="co"># The mean should be 100 but, in reality, it is not precise, so we calculate it and put in the #object ‘iq_m’</span></a>
<a class="sourceLine" id="cb366-2" title="2">iq_m&lt;-<span class="kw">mean</span>(prisoner_iq<span class="op">$</span>IQ) </a>
<a class="sourceLine" id="cb366-3" title="3"></a>
<a class="sourceLine" id="cb366-4" title="4"><span class="co"># Same with sd; it should be 15 but we calculate it to get a precise estimate and put in object #‘iq_sd’</span></a>
<a class="sourceLine" id="cb366-5" title="5">iq_sd&lt;-<span class="kw">sd</span>(prisoner_iq<span class="op">$</span>IQ) </a>
<a class="sourceLine" id="cb366-6" title="6"></a>
<a class="sourceLine" id="cb366-7" title="7"><span class="co"># Enter the prisoner’s IQ score and specify ‘below’ following ‘region’ because we are </span></a>
<a class="sourceLine" id="cb366-8" title="8"><span class="co"># interested in IQ scores below 124</span></a>
<a class="sourceLine" id="cb366-9" title="9"><span class="kw">pnormGC</span>(<span class="dv">124</span>, <span class="dt">region=</span><span class="st">&quot;below&quot;</span>, <span class="dt">mean=</span>iq_m, <span class="dt">sd=</span>iq_sd,<span class="dt">graph=</span><span class="ot">TRUE</span>) </a></code></pre></div>
<p><img src="06-hypotheses_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<pre><code>## [1] 0.9451812</code></pre>
<p>The output shows the shaded area at 0.9453, meaning that the prisoner has a higher IQ than over 94% of the prison population.</p>
<p>Recall from the previous week, the 68-95-99.7 rule. This is helpful to keep in mind with z-scores, as a z-score indicates how far away a score is from the mean based on the standard normal distribution. The rule posits that 68% of cases in the distribution fall within one standard deviation above and below the mean; 95% within two SD; and 99.7% within 3 SD. We demonstrate this rule by using the <code>pnormGC()</code> function to get the proportion of prisoners that have an IQ between 85 to 115, which is one SD above and below the mean:</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb368-1" title="1"><span class="co"># Specify ‘between’ for ‘region’ because we are interested in proportion of prisoners between the two given values</span></a>
<a class="sourceLine" id="cb368-2" title="2"><span class="kw">pnormGC</span>(<span class="dt">bound=</span><span class="kw">c</span>(<span class="dv">85</span>, <span class="dv">115</span>),<span class="dt">region=</span><span class="st">&quot;between&quot;</span>, <span class="dt">mean=</span><span class="dv">100</span>,<span class="dt">sd=</span><span class="dv">15</span>,<span class="dt">graph=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="06-hypotheses_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre><code>## [1] 0.6826895</code></pre>
<p>And, yes, it shows that 68% of the IQ scores do fall within +/-1 standard deviation of the mean, in the case of a normal distribution.</p>
<hr />
</div>
<div id="activity-9-single-sample-z-tests-for-means" class="section level4">
<h4><span class="header-section-number">6.2.3.2</span> Activity 9: Single sample z-tests for means</h4>
<p>So how can we use this to test hyptheses? Returning to the parole board example, say if the officer wanted to know, with 99% confidence, if the average IQ at this specific prison is significantly different from those of all prisons in the UK.</p>
<p>Let’s say that we have a prison with a random selection of 233 prisoners. Let’s sample this now from our population.</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb370-1" title="1"><span class="kw">library</span>(mosaic)</a>
<a class="sourceLine" id="cb370-2" title="2"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb370-3" title="3">prison_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">sample</span>(prisoner_iq, <span class="dv">233</span>)</a></code></pre></div>
<p>The officer conducts an IQ assessment of all 233 prisoners at their prison and finds average IQ is 98.3819742 (SD = 15.1818012).</p>
<p>As the population parameter (mean IQ for all prisoners) is known (it is 100, see our simulated population data above), a <strong>single sample z-test</strong> is appropriate. This test examines whether a sample is drawn from a specific population with a known or hypothesized mean. Here are the officer’s hypotheses:</p>
<p><span class="math inline">\(H_0\)</span>: The mean IQ of the population from which our sample of prisoners was drawn is the same as the mean IQ of the UK prison population (mean = 100).</p>
<p><span class="math inline">\(H_A\)</span>: The mean IQ of the population from which our sample of prisoners was drawn is not the same as the mean IQ of the UK prison population (mean ≠ 100).</p>
<blockquote>
<p>Note: we ‘know’ the population mean because we made a hypothetical population. We might not know this in real life, but our hypothetical officer might have a <em>hypothesis</em> that the population mean is 100 IQ. We can test against this hypothesised population mean.</p>
</blockquote>
<p>How can we test this? Well we need to calculate a z-test statistic. To calculate the z-test statistic we need the following parameters: the sample mean (<span class="math inline">\(\bar{x}\)</span>), the sample standard deviation (<span class="math inline">\(\sigma\)</span>), the sample size (<span class="math inline">\(n\)</span>), and the known (or hypothesised) population mean (<span class="math inline">\(\mu\)</span>). The equation to calculate the z-test statistic is as follows:</p>
<p><span class="math inline">\(z = \frac{\bar{x}-\mu}{\sigma/\sqrt{n}}\)</span></p>
<p>So the difference between the sample mean and the population mean over the standard deviation divided by the square root of the sample size.</p>
<p>To compute this in R first we need each of these values:</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb371-1" title="1">xbar &lt;-<span class="st"> </span><span class="kw">mean</span>(prison_<span class="dv">1</span><span class="op">$</span>IQ) <span class="co"># sample mean</span></a>
<a class="sourceLine" id="cb371-2" title="2">mu &lt;-<span class="st"> </span><span class="dv">100</span> <span class="co"># (hypothesised) population mean</span></a>
<a class="sourceLine" id="cb371-3" title="3">iq_sd &lt;-<span class="st"> </span><span class="kw">sd</span>(prison_<span class="dv">1</span><span class="op">$</span>IQ) <span class="co"># sample standard deviation </span></a>
<a class="sourceLine" id="cb371-4" title="4">sample_size &lt;-<span class="st"> </span><span class="kw">nrow</span>(prison_<span class="dv">1</span>) <span class="co"># the number of prisoners in our sample</span></a></code></pre></div>
<p>We can now compute our test statistic using the parameters calculated above.</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb372-1" title="1"> z_stat &lt;-<span class="st"> </span>(xbar<span class="op">-</span>mu) <span class="op">/</span><span class="st"> </span>(iq_sd <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(sample_size)) <span class="co"># Equation for one-sample z-test</span></a>
<a class="sourceLine" id="cb372-2" title="2"></a>
<a class="sourceLine" id="cb372-3" title="3">z_stat</a></code></pre></div>
<pre><code>## [1] -1.626822</code></pre>
<!-- We create our own function called ' z_test ' so that other prisons can easily compare their IQ scores to that of all prisoners. In addition, we use `cat()`, which combines our string text to label our z-score in the output and the computed z-score together. -->
<!-- The function we create `z_test()` will take as parameters the sample mean (xbar), the sample standard deviation (sd), the sample size (n), and the known (or hypothesised) population mean (mu):  -->
<!--  z <- (xbar-mu) / (sd / sqrt(n))  -->
<!-- ```{r} -->
<!-- # Specifying inputs in the order that the user needs to enter them : sample mean, standard deviation,number of prisons, and the population mean that the sample mean to which it will be compared -->
<!-- z_test<-function(xbar, sd, n, mu) {  -->
<!--   z <- (xbar-mu) / (sd / sqrt(n)) # Equation for one-sample z-test -->
<!--   return(cat('z =', z)) # Report z-score to the user -->
<!-- } # End function -->
<!-- # Test it with our example by supplying estimates  -->
<!-- z_test(xbar, iq_sd, 233, 100) -->
<!-- ``` -->
<!-- Including the p-value would be helpful so we edit our code and use the function `pnorm()` to compute the probability value.  -->
<!-- ``` {r} -->
<!-- # Same as above -->
<!-- z_test<-function(xbar, sd, n, mu) {  -->
<!-- z <- (xbar-mu) / (sd / sqrt(n))  -->
<!-- # This is the new bit: we multiply ‘pnorm’ by 2 to indicate that our hypothesis is non-directional  -->
<!-- p<-2 * pnorm(-abs(z))  -->
<!-- return( cat('z =', z,  -->
<!-- '\np-value =', p)) # Added code to return p-value -->
<!-- }  -->
<!-- # Test it with our example again  -->
<!-- z_test(103, 18, 233, 100) -->
<!-- ``` -->
<p>So we get this test statistic of -1.6268222, but how can we interpret this? Well you can use this z-test statistic to find <em>the associated p-value</em>. How can we do that?</p>
<p>The traditional way (something about <em>back in my day…!!</em> ha) is to look up the associated p-value with each z-score in the back of a textbook - which usually would contain a <a href="https://www.math.arizona.edu/~rsims/ma464/standardnormaltable.pdf">z-table</a></p>
<p>If you look at the table above, you will see, for a score of -0.7, at <span class="math inline">\(\alpha = 0.05\)</span> the associated value in the table linked above is <em>0.22663</em> (rougly 0.23). This is greater than the alpha of 0.05, and so we <em>cannot reject the null hypothesis</em>.</p>
<p>There is another way to find the p-value. The z-statistic is in fact a z-score on a normal distribution. And the p-value is the probability of seeing these outcomes if the null hypotheses were true. We can refer back to our <code>pnormGC()</code> function, to see what this value may be:</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb374-1" title="1"><span class="kw">pnormGC</span>(z_stat, <span class="dt">region=</span><span class="st">&quot;below&quot;</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>, <span class="dt">graph=</span><span class="ot">TRUE</span>) </a></code></pre></div>
<p><img src="06-hypotheses_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<pre><code>## [1] 0.05188743</code></pre>
<p>You can see that the value is 0.2302. This is a more precise approximation than our lookup table (where we had to round -1.6268222 to -0.7), and so we are getting a more precise p-value.</p>
<p>But also did we specify a direction? We did not! So actually, we should be looking at a two-tailed probabiity:</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb376-1" title="1"><span class="kw">pnormGC</span>(<span class="dt">bound=</span><span class="kw">c</span>(z_stat, <span class="op">-</span>z_stat), <span class="dt">region=</span><span class="st">&quot;outside&quot;</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">1</span>, <span class="dt">graph=</span><span class="ot">TRUE</span>) </a></code></pre></div>
<p><img src="06-hypotheses_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<pre><code>## [1] 0.1037749</code></pre>
<p>You will see our value has increased to 0.4602. In fact, this is simply 2 times the original p-value we got (<span class="math inline">\(2*0.23 = 0.46\)</span>). You can also see here that the <em>two tails</em> of the distribution are shaded as our non-directional hypothesis is a two-tailed test!</p>
<p>Above, when we were looking at a directional hypothesis, it only took into consideration <em>one tail</em> of the distribution, hence it being called a one-tailed test! <em>mind.blown</em></p>
<p>Now you don’t usually need the visualisation for this, we just included it to help learn the concepts. We can get our associated p-value with the z_statistic using the <code>pnorm()</code> function:</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb378-1" title="1"><span class="kw">pnorm</span>(z_stat)</a></code></pre></div>
<pre><code>## [1] 0.05188743</code></pre>
<p>And since we have a non-directional hypothesis, we times this by two (we’re interested in TWO-TAILED hypotheses):</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb380-1" title="1"><span class="kw">pnorm</span>(z_stat)<span class="op">*</span><span class="dv">2</span></a></code></pre></div>
<pre><code>## [1] 0.1037749</code></pre>
<p>Now a final thing -
Remember that the officer wanted to be 99% confident, and this means that the significance level would be set at <span class="math inline">\(\alpha\)</span> = 0.01 and not <span class="math inline">\(\alpha\)</span> = 0.05 (this is if we are 95% confident). However, at this point still, our p-value is greater than the alpha level so we fail to reject the null hypothesis.</p>
<hr />
<!-- #### Activity 10: Single Sample z-tests for Proportions -->
<!-- Our next example is to do with evaluating a new prison education programme. The foundation supporting the programme would like to achieve a success rate of 75% among 100,000 prisoners participating in he programme. Success is defined as completion of the six-month course.  -->
<!-- After the programme ran, there is conflicting information about its success: managers of the programme claim they achieved higher than the 75% success rate, while a journalist investigating the programme claimed it was below 75%. You want to get to the bottom of this, so you collect information from 150 of the prisoners who enrolled on the programme using independent random sampling.  -->
<!-- Your data shows that 85% of the participants successfully completed the programme. What to make of your result? Let’s set up the hypotheses where we want a non-directional alternative hypothesis: -->
<!-- $H_0$: The success rate of the program is 0.75% (P = 0.75).  -->
<!-- $H_A$: The success rate of the program is not 0.75% (P ≠ 0.75) -->
<!-- To test this, we use a **single-sample z-test for proportions** because we are concerned with comparing the percentages or proportions between our sample and the known population. We create another new function: -->
<!-- ```{r} -->
<!-- # Specifying inputs: p is proportion of success, P is proportion of success in population, n is sample size -->
<!-- prop_z_test<-function(p, P, n) {  -->
<!-- Numerator<-(p - P)  -->
<!-- PQ<- P * (1-P)  -->
<!-- # Standard error -->
<!-- Denominator<-sqrt(PQ / n)  -->
<!-- z<- Numerator / Denominator  -->
<!-- # Return the z-value and p-value to the user -->
<!-- p<-2 * pnorm(-abs(z))  -->
<!-- return( cat('z =', z,  -->
<!-- '\np-value =', p))  -->
<!-- }  -->
<!-- # Let's test it using the values from our problem  -->
<!-- prop_z_test(0.85, 0.75, 150) -->
<!-- ``` -->
<!-- The z-score is 2.828427 and the p-value is statistically significant. We reject the null hypothesis and conclude that the success rate is not 75%.  -->
<!-- --- -->
<!-- #### Activity 11: Single-sample t-tests for Means -->
<!-- When the population parameter is unknown and we want to compare our sample to it, we use the t-distribution. From the previous example, let us say that average test scores were also collected for those prisoners who completed the six-month education course.  -->
<!-- The foundation defined success as 65 for the test. Again, managers claimed the average scores were higher than this, whereas the journalist claimed the average was below 65. You have collected test score information from 50 prisoners and find that the mean is 60 and SD is 15. What conclusions can be made about the *larger population of prisoners* at the 95% confidence level? -->
<!-- *Hypotheses* -->
<!-- $H_0$: The mean test score for prisoners who have completed the program is 65 (μ = 65). -->
<!-- $H_A$: The mean test score for prisoners who have completed the program is not 65 (μ ≠ 65). -->
<!-- We conduct a **single-sample t-test for means**, which is similar to the previous z-tests except it is for an unknown population, which in this case, is the overall population of prisoners and not just the ones who had completed the six-month education programme. We modify the code from the `z_test ()` function: -->
<!-- ```{r} -->
<!-- # Specifying inputs: xbar is sample mean, sd is sample standard deviation, n is sample size, mu is defined by null hypothesis and is 65 -->
<!-- single_t_test<-function(xbar, sd, n, mu) {  -->
<!-- # Equation for one-sample z-test -->
<!-- t <- (xbar-mu) / (sd / sqrt(n - 1))  -->
<!-- # Report t-score and p-value to the user -->
<!-- p<-2 * pnorm(-abs(t))  -->
<!-- return( cat('t =', t,  -->
<!-- '\np-value =', p)) -->
<!-- }  -->
<!-- # Test it with our example  -->
<!-- single_t_test(60, 15, 51, 65) -->
<!-- ``` -->
<!-- The t-value of -2.357023 is statistically significant, so we have sufficient support to reject the null hypothesis. We conclude that the mean test score for prisoners who completed the programme is not 65.  -->
<hr />
</div>
</div>
</div>
<div id="summary-5" class="section level2">
<h2><span class="header-section-number">6.3</span> SUMMARY</h2>
<p>Today, we learned that to make predictions about the population from our sample, we must create <strong>hypotheses</strong>. When we test our hypothesis, we aspire to reject the <strong>null hypothesis</strong>, which tells us no differences exist. To ensure we reject the null accurately, however, we must be wary of <strong>type 1 error</strong> so we consider this error in tests of <strong>statistical significance</strong> and in evaluating our <strong>p-values</strong>. These hypothesis tests we learned today in <code>R</code> used the <strong>binomial distribution</strong> as well as the normal distribution, and required us to set our hypotheses at the outset as either <strong>directional</strong> or <strong>non-directional</strong>. Hypothesis tests that used the normal distribution were explored for <strong>single samples</strong> and statistical significance was determined by <strong>z scores</strong> . In most cases going forward, the functions we use in R will be computing p-values for you, but it’s important to understand what these are, where they come from, and what they mean, to be able to correctly interpret these.</p>
<p>Homework time…</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inferential-statistics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="relationships-with-categorical-variables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/06-hypotheses.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Modelling-Crime-Data-2021.pdf", "Modelling-Crime-Data-2021.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
